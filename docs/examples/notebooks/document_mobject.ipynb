{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IByYhgKy9WCo"
   },
   "source": [
    "# Document MObject Example\n",
    "This Jupyter notebook runs on Colab after adding HF_TOKEN as secret to Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIu6B1Ht927Z"
   },
   "source": [
    "## Install Ollama\n",
    "\n",
    "Before we get started with Mellea, we download and install ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDaTfltQY3Fl"
   },
   "outputs": [],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "!nohup ollama serve &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEl3nAk696mI"
   },
   "source": [
    "## Install Mellea\n",
    "We run `uv pip install mellea` to install Mellea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EurAUSz_1yl"
   },
   "outputs": [],
   "source": [
    "!uv pip install mellea -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NU7bZqKA0djW"
   },
   "source": [
    "## Create a RichDocument\n",
    "Let's create a RichDocument from an arxiv paper, which loads the PDF file and parses it with the Docling parser into an intermediate representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3j-Se7PpfMqV"
   },
   "outputs": [],
   "source": [
    "from mellea.stdlib.docs.richdocument import RichDocument\n",
    "rd = RichDocument.from_document_file(\"https://arxiv.org/pdf/1906.04043\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a Table from the Document\n",
    "We can extract some document content, e.g. the first table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcBb3g_BfMqV"
   },
   "outputs": [],
   "source": [
    "from mellea.stdlib.docs.richdocument import Table  # noqa: E402\n",
    "table1: Table = rd.get_tables()[0]\n",
    "print(table1.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGPC471ufMqW"
   },
   "source": [
    "## Work with the Table Object\n",
    "The Table object is Mellea-ready and can be used immediately with LLMs. In this example, table1 is transformed to have an extra column \"Model\" which contains the model string from the Feature column or \"None\" if there is none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHI3E7G9fMqX"
   },
   "outputs": [],
   "source": [
    "from mellea import start_session  # noqa: E402\n",
    "from mellea.backends.types import ModelOption  # noqa: E402\n",
    "m = start_session()\n",
    "for seed in [x * 12 for x in range(5)]:\n",
    "    table2 = m.transform(\n",
    "        table1,\n",
    "        \"Add a column 'Model' that extracts which model was used or 'None' if none.\",\n",
    "        model_options={ModelOption.SEED: seed},\n",
    "    )\n",
    "    if isinstance(table2, Table):\n",
    "        print(table2.to_markdown())\n",
    "        break\n",
    "    else:\n",
    "        print(\"==== TRYING AGAIN after non-useful output.====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has fulfilled the task and coming back with a parsable syntax. You could now call (e.g. m.query(table2, \"Are there any GPT models referenced?\")) or continue transformation (e.g. m.transform(table2, \"Transpose the table.\"))."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
